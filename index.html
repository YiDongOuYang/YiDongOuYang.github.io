<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yidong Ouyang</title>
  
  <meta name="author" content="Yidong Ouyang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yidong Ouyang</name>
              </p>
              <p>Hey, I am Yidong Ouyang, a Ph.D. student at UCLA where I am fortunate to be advised by <a href="http://www.stat.ucla.edu/~guangcheng/">Guang Cheng</a>. Prior to this, I earned my MPhil from CUHK Shenzhen, where I was advised by <a href="https://liyanxie.github.io/">Liyan Xie</a>. My research interests lie in Generative Models, especially diffusion models.
              </p>
              <!--
              <p>
                During undergrad, I worked with <a href="https://dblp.org/pid/93/1549.html">Weiyu Guo</a> on regularization in spectral domain and model compression. And I visited Westlake University to work on the domain generalization project under Professor <a href="https://en.westlake.edu.cn/academics/School_of_Engineering/About/Our_People/Faculty/201912/t20191206_2513.shtml">Donglin Wang</a>’s supervision. 
                I also collaborated with <a href="http://jd92.wang/">Jindong Wang</a> during my visit to the Institute of Computing Technology, Chinese Academic of Science.
                I've received the National Scholarship in 2018.
              </p>
              --> 
              <p style="text-align:center">
                <a href="mailto:yidongouyang@g.ucla.edu">Email</a> &nbsp/&nbsp
                <a href="data/Yidong_Ouyang_Resume_9.28.pdf">CV</a> &nbsp/&nbsp
                <a href="https://github.com/YiDongOuYang">Github</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&view_op=list_works&gmla=ABEO0YojTeBVJ9vE9IIUJ8GfeiV93Wz2VyTVgDfigpOtRTyj2avSXKHQcrHYg8QDjzdnmDg189FMyGF_g8tPQ9hdQQWpmCUbxM0YzIsFx0JN&user=fQwCFK0AAAAJ">Google Scholar</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Yidong.JPG"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Yidong.JPG" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <!--
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Recent News</heading>
              <p>[July 2024] Invited to be a Program Committee for AAAI 2025.</p>
              <p>[May 2023] One conference paper Improving Adversarial Robustness by Contrastive Guided Diffusion Process and one workshop paper MissDiff: Training Diffusion Models on Tabular Data with Missing Values accepted to ICML 2023.</p>
    
            </td>
          </tr>
        </tbody></table>
        --> 
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            

            <td style="padding:20px;width:75%;vertical-align:middle">
              
                <papertitle>Discrete Guidance Matching: Exact Guidance and its Application to Human Preference Alignment</papertitle>
              
              <br>
              <strong>Yidong Ouyang*</strong>,
              Zhengyan Wan*, Liyan Xie, Fang Fang, Hongyuan Zha, Guang Cheng
              <br>

              
              <br>
              <a href="https://arxiv.org/abs/2509.21912">arxiv</a> <a href="https://github.com/WanZhengyan/Discrete-Guidance-Matching/tree/main">code</a>
              <p></p>
              <p> We derive the exact transition rate for the desired distribution given a learned discrete flow matching model, leading to guidance that only requires a single forward pass in each sampling step. </p>
             </td>
            </tr> 
          <tr>
            

            <td style="padding:20px;width:75%;vertical-align:middle">
              
                <papertitle>Error Analysis of Discrete Flow with Generator Matching</papertitle>
              
              <br>
              Zhengyan Wan,
              <strong>Yidong Ouyang</strong>,
              Qiang Yao, Liyan Xie, Fang Fang, Hongyuan Zha, Guang Cheng
              <br>

              
              <br>
              <a href="https://arxiv.org/abs/2509.21906">arxiv</a> 
              <p></p>
              <p> We derive the KL divergence of two path measures regarding two continuous-time Markov chains (CTMCs) with different transition rates by developing a novel Girsanov-type theorem, and provide a comprehensive analysis that encompasses the error arising from transition rate estimation and early stopping. </p>
             </td>
            </tr> 
          
          <tr>
            

            <td style="padding:20px;width:75%;vertical-align:middle">
              
                <papertitle>Transfer Learning for Diffusion Models</papertitle>
              
              <br>
              <strong>Yidong Ouyang</strong>,
              Liyan Xie,
              Hongyuan Zha, 
              Guang Cheng
              <br>
               <em>NeurIPS 2024</em>. 
              
              <br>
              <a href="https://arxiv.org/abs/2405.16876">arxiv</a> <a href="https://github.com/YiDongOuYang/Transfer-Learning-for-Diffusion-Models">code</a>
              <p></p>
              <p> We prove that the optimal diffusion model for the target domain integrates pre-trained diffusion models on the source domain with additional guidance from a domain classifier. We further extend TGDP to a conditional version for modeling the joint distribution of data and its corresponding labels, together with two additional regularization terms to enhance the model performance. </p>
             </td>
            </tr> 
          
          
          <tr>
            

            <td style="padding:20px;width:75%;vertical-align:middle">
              
                <papertitle>MissDiff: Training Diffusion Models on Tabular Data with Missing Values</papertitle>
              
              <br>
              <strong>Yidong Ouyang</strong>,
              Liyan Xie,
              Chongxuan Li,
              Guang Cheng
              <br>
               <em>ICML workshop on Structured Probabilistic Inference & Generative Modeling 2023</em>. 
              
              <br>
              <a href="https://arxiv.org/abs/2307.00467">arxiv</a> <a href="https://github.com/YiDongOuYang/MissDiff">code</a>
              <p></p>
              <p> We first observe that the widely adopted "impute-then-generate" pipeline may lead to a biased learning objective. Then we propose to mask the regression loss of Denoising Score Matching in the training phase. We prove the proposed method is consistent in learning the score of data distributions, and the proposed training objective serves as an upper bound for the negative likelihood in certain cases. </p>
             </td>
            </tr> 
          
          <tr>
            
            <td style="padding:20px;width:75%;vertical-align:middle">
              
                <papertitle>Improving Adversarial Robustness Through the Contrastive-Guided Diffusion Process</papertitle>
              
              <br>
              <strong>Yidong Ouyang</strong>,
              Liyan Xie,
              Guang Cheng
              <br>
               <em>ICML 2023</em>. 
              
              <br>
              <a href="https://arxiv.org/abs/2210.09643">arxiv</a> <a href="https://github.com/YiDongOuYang/Contrastive-Guided-Diffusion-Process">code</a>
              <p></p>
              <p> We first analyze the optimality condition of synthetic distribution for achieving non-trivial robust accuracy. We show that enhancing the distinguishability among the generated data is critical for improving adversarial robustness. Thus, we propose the Contrastive-Guided Diffusion Process (Contrastive-DP), which adopts the contrastive loss to guide the diffusion model in data generation.</p>
             </td>
            </tr> 
          
           <tr>
            

            
            <td style="padding:20px;width:75%;vertical-align:middle">
              
                <papertitle>Attention Enables Zero Approximation Error</papertitle>
              
              <br>
              Zhiying Fang,
              <strong>Yidong Ouyang</strong>,
              Ding-Xuan Zhou,
              Guang Cheng
              <br>

              <br>
              <a href="https://arxiv.org/pdf/2202.12166.pdf">arxiv</a>
              <p></p>
              <p> We theoretically prove the self-attention model can achieve zero approximation error. Moreover, our proposed model can avoid the classical trade-off between approximation error and sample error in the mean squared error analysis.</p>
            </td>
          </tr> 
        
        
          <tr>
            

            <td style="padding:20px;width:75%;vertical-align:middle">
              
                <papertitle>Generalizing to Unseen Domains: A Survey on Domain Generalization</papertitle>
              
              <br>
              Jindong Wang,
              Cuiling Lan,
              Chang Liu,
              <strong>Yidong Ouyang</strong>,
              Tao Qin
              <br>
           <em> IEEE TKDE, IJCAI 2021 survey track</em>. 
              <br>
              <a href="https://arxiv.org/pdf/2103.03097.pdf">arxiv</a>
              <p></p>
              <p> We presents the first review for recent advances in domain generalization, including the theory of generalization, the taxonomy of domain generalization methods, and the potential research topics.</p>
            </td>
          </tr> 
          
          <tr>
            
            <td style="padding:20px;width:75%;vertical-align:middle">
              
                <papertitle>Domain Generalization by Dropping Spurious Information out</papertitle>
              
              <br>
              <strong>Yidong Ouyang</strong>,
              Siteng Huang,
              Jindong Wang,
              Donglin Wang
              <br>
        <!--   <em>ICML 2020 Workshop on Uncertainty and Robustness in Deep Learning</em>. -->
              <br>
              <a href="data/DG.pdf">paper</a>
              <p></p>
              <p> We propose a mutual information maximum module to explicitly drop superfluous information related to the domain labels. 
                We thoroughly reviewed our methods from both theoretical and empirical perspective and demonstrated the connections and advantages to domain adversarial training and triplet loss.</p>
            </td>
          </tr> 

            <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              
                <papertitle>Robust Learning with Frequency Domain Regularization</papertitle>
              
              <br>
              <strong>Yidong Ouyang</strong>,
              Weiyu Guo, 
              Adam Dziedzic, 
              Sanjay Krishnan.
              <br>
        <!--  <em>In Submission</em>. -->
              <br>
              <a href="https://arxiv.org/abs/2007.03244">paper</a>
              <p></p>
              <p> We investigated the regularization technique from a Fourier perspective and pinpointed an extreme small but valid spectral range for different layers. our regularization technique reduces the generalization gap on computer vision benchmarks and improves the robustness of models, especially against low frequency attack.</p>
            </td>
          </tr> 


    
          <tr>
            
            <td style="padding:20px;width:75%;vertical-align:middle">

                <papertitle> Learning Efficient Convolutional Networks through Irregular Convolutional Kernels</papertitle>

              <br>
              Weiyu Guo, 
              Jiabin Ma, 
              <strong>Yidong Ouyang</strong>, 
              Liang Wang, 
              Yongzhen Huang.
              <br>
              <em>Neurocomputing</em>. 
              <br>
              <a href= https://www.sciencedirect.com/science/article/pii/S0925231222002338>paper</a>
        



              <p> We propose RotateConv kernels as an interpolation-based method that transforms traditional square kernels to line segments. Our approach can massively reduce the number of
parameters and calculations while maintaining acceptable performance.</p>
              <p>
              </p>
            </td>
          </tr>  

        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Machine Learning Workshops & Reading Groups</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            Some of the workshops and other reading groups I've given:
            <td width="75%" valign="center">
              <a href="data/Diffusion Model for Solving Schrödinger Bridge Problem.pdf">Diffusion Model for Solving Schrödinger Bridge Problem</a>, CUHKSZ, 2023.5.28.
              <br>
              <br>
              <a href="data/synthetic data generation 8.26.pdf">Synthetic generation for tabular data</a>, CUHKSZ, 2022.8.26.
              <br>
              <br>
              <a href="data/All about OOD generalization I--invariant representation 2021.8.24.pdf">All about OOD generalization I--invariant representation</a>, CUHKSZ, 2021.8.24.
              <br>
              <br>
              <a href="data/Regularization in Spectral Domain.pptx">Regularization in Spectral Domain</a>, CUFE, 2020.12.
              <br>
              <br>
              <!-- <a href="data/Intro to deep learning.pptx">Intro to deep learning</a>, CUFE, 2020.4.
              <br>
              <br>-->
            </td>
          <tr>
        </tbody></table>
        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Teaching</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            
            <td width="75%" valign="center">
              Teaching Assistant, STA3020 Statistical Inference</a> 2021, CUHKSZ. <br>
              Teaching Assistant, DDA4010 Bayesian Statistics</a> 2022, CUHKSZ. 
            </td>
          <tr>
          <tr>

          
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Service</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            
            <td width="75%" valign="center">
              Conference reviewer: NeurIPS 2023, 2024, ICLR 2024, 2025, ICML 2024, AAAI 2025<br>
              Journal reviewer: TNNLS, TKDE
            </td>
          <tr>
          <tr>

          
          </tr>
        </tbody></table>

        
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=3Cad_DDxp_fycoW3NTfOM5Z9wsHXlf4nUOwIK7IY3ok&cl=ffffff&w=a"></script>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Website credits go to  <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>!
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>
</html>
